# Домашнее задание к занятию «Микросервисы: подходы» - Барышков Михаил

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Задача 1: Обеспечить разработку

**Предлагаемое решение:** GitLab Ultimate + GitLab Runner

### Компоненты решения:
- **GitLab SaaS** (облачная версия) или **GitLab Self-Managed**
- **GitLab CI/CD** (встроенная система непрерывной интеграции и поставки)
- **GitLab Container Registry** (для докер-образов)
- **GitLab Runner** (агенты сборки)

### Соответствие требованиям:

| Требование | Реализация в GitLab |
|------------|---------------------|
| Облачная система | GitLab SaaS или self-managed в облаке |
| Система контроля версий Git | Встроенная поддержка Git |
| Репозиторий на каждый сервис | Неограниченное количество репозиториев |
| Запуск сборки по событию из системы контроля версий | Автоматические пайплайны при push, merge request |
| Запуск сборки по кнопке с указанием параметров | Manual jobs с параметрами |
| Настройки к каждой сборке | Переменные окружения на уровне проекта/пайплайна |
| Шаблоны для конфигураций сборок | Includes, templates, reusable configurations |
| Безопасное хранение секретных данных | Protected Variables, интеграция с HashiCorp Vault |
| Несколько конфигураций из одного репозитория | Multiple .gitlab-ci.yml, child pipelines |
| Кастомные шаги при сборке | Полная кастомизация через .gitlab-ci.yml |
| Собственные докер-образы для сборки | Container Registry для хранения образов |
| Агенты сборки на собственных серверах | Развертывание GitLab Runner |
| Параллельный запуск нескольких сборок | Параллельное выполнение jobs и stages |
| Параллельный запуск тестов | Parallel:matrix для параллельного тестирования |

### Преимущества:
- Единая платформа для всего DevOps цикла
- Встроенный Container Registry
- Security scanning
- Package registry
- Интеграция с Kubernetes

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Задача 2: Логи

**Предлагаемое решение:** EFK Stack (Elasticsearch, Fluentd, Kibana) + Kafka

### Компоненты решения:
- **Fluentd/Fluent Bit** - сбор и агрегация логов
- **Kafka** - буферизация для гарантированной доставки
- **Elasticsearch** - хранение и индексация логов
- **Kibana** - веб-интерфейс для анализа

### Архитектура:

Приложения → Fluent Bit (на хостах) → Kafka → Fluentd → Elasticsearch → Kibana

↑

Docker stdout

### Соответствие требованиям:

| Требование | Реализация в EFK Stack |
|------------|---------------------|
| Сбор логов в центральное хранилище | Fluentd/Fluent Bit собирает логи со всех хостов |
| Минимальные требования к приложениям | Сбор из stdout через Docker logging drivers |
| Гарантированная доставка логов | Kafka как буфер предотвращает потерю данных |
| Поиск и фильтрация по записям | Мощный поиск Elasticsearch |
| UI с доступом для разработчиков | Kibana с ролевым доступом |
| Ссылка на сохраненный поиск | Saved Searches в Kibana |

### Альтернативные решения:
- **Loki + Grafana** - более легковесное решение
- **Splunk** - коммерческое решение enterprise-уровня


## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Задача 3: Мониторинг

**Предлагаемое решение:** Prometheus + Grafana + Alertmanager

### Компоненты решения:
- **Prometheus** - сбор и хранение метрик
- **Grafana** - визуализация и дашборды
- **Alertmanager** - управление оповещениями
- **Node Exporter** - метрики хостов
- **cAdvisor** - метрики контейнеров

### Архитектура мониторинга:
Node Exporter + cAdvisor → Prometheus → Grafana

↑

Application Metrics (custom exporters)

### Соответствие требованиям:

| Требование | Реализация в Prometheus Stack |
|------------|-----------------------------|
| Сбор метрик со всех хостов | Node Exporter на каждом хосте |
| Метрики состояния ресурсов хостов | CPU, RAM, HDD, Network через Node Exporter |
| Метрики потребляемых ресурсов сервисами | cAdvisor для контейнеров |
| Специфичные метрики для каждого сервиса | Custom exporters, application metrics |
| UI с запросами и агрегацией | PromQL в Prometheus и Grafana |
| Настраиваемые панели для отслеживания | Grafana dashboards |

### Дополнительные компоненты:
- **VictoriaMetrics** - для долгосрочного хранения
- **Thanos/Cortex** - для масштабирования Prometheus
- **Blackbox Exporter** - для мониторинга сетевых сервисов

### Ключевые преимущества:
- Pull-модель сбора метрик
- Мощный язык запросов PromQL
- Широкая экосистема экспортеров
- Автоматическое обнаружение сервисов
- Интеграция с Kubernetes
- Активное сообщество и готовые дашборды


## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
